(self.webpackChunkguzzle=self.webpackChunkguzzle||[]).push([[4131],{3905:function(t,e,r){"use strict";r.d(e,{Zo:function(){return u},kt:function(){return f}});var a=r(7294);function n(t,e,r){return e in t?Object.defineProperty(t,e,{value:r,enumerable:!0,configurable:!0,writable:!0}):t[e]=r,t}function o(t,e){var r=Object.keys(t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(t);e&&(a=a.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),r.push.apply(r,a)}return r}function l(t){for(var e=1;e<arguments.length;e++){var r=null!=arguments[e]?arguments[e]:{};e%2?o(Object(r),!0).forEach((function(e){n(t,e,r[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(r,e))}))}return t}function i(t,e){if(null==t)return{};var r,a,n=function(t,e){if(null==t)return{};var r,a,n={},o=Object.keys(t);for(a=0;a<o.length;a++)r=o[a],e.indexOf(r)>=0||(n[r]=t[r]);return n}(t,e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(t);for(a=0;a<o.length;a++)r=o[a],e.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(t,r)&&(n[r]=t[r])}return n}var s=a.createContext({}),c=function(t){var e=a.useContext(s),r=e;return t&&(r="function"==typeof t?t(e):l(l({},e),t)),r},u=function(t){var e=c(t.components);return a.createElement(s.Provider,{value:e},t.children)},p={inlineCode:"code",wrapper:function(t){var e=t.children;return a.createElement(a.Fragment,{},e)}},d=a.forwardRef((function(t,e){var r=t.components,n=t.mdxType,o=t.originalType,s=t.parentName,u=i(t,["components","mdxType","originalType","parentName"]),d=c(r),f=n,m=d["".concat(s,".").concat(f)]||d[f]||p[f]||o;return r?a.createElement(m,l(l({ref:e},u),{},{components:r})):a.createElement(m,l({ref:e},u))}));function f(t,e){var r=arguments,n=e&&e.mdxType;if("string"==typeof t||n){var o=r.length,l=new Array(o);l[0]=d;var i={};for(var s in e)hasOwnProperty.call(e,s)&&(i[s]=e[s]);i.originalType=t,i.mdxType="string"==typeof t?t:n,l[1]=i;for(var c=2;c<o;c++)l[c]=r[c];return a.createElement.apply(null,l)}return a.createElement.apply(null,r)}d.displayName="MDXCreateElement"},6499:function(t,e,r){"use strict";r.r(e),r.d(e,{frontMatter:function(){return i},metadata:function(){return s},toc:function(){return c},default:function(){return p}});var a=r(2122),n=r(9756),o=(r(7294),r(3905)),l=["components"],i={},s={unversionedId:"How to guides/Datastores/Azure Data Factory",id:"How to guides/Datastores/Azure Data Factory",isDocsHomePage:!1,title:"Azure Data Factory",description:"Azure Data Factory is the platform that solves such data scenarios. It is the cloud-based ETL and data integration service that allows you to create data-driven workflows for orchestrating data movement and transforming data at scale.",source:"@site/docs/How to guides/Datastores/Azure Data Factory.md",sourceDirName:"How to guides/Datastores",slug:"/How to guides/Datastores/Azure Data Factory",permalink:"/docs/docs/How to guides/Datastores/Azure Data Factory",editUrl:"https://github.com/ja-guzzle/docs/blob/master/docs/How to guides/Datastores/Azure Data Factory.md",version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Amazon S3",permalink:"/docs/docs/How to guides/Datastores/Amazon S3"},next:{title:"Azure Data Lake Storage Gen2",permalink:"/docs/docs/How to guides/Datastores/Azure Data Lake Storage Gen2"}},c=[{value:"Steps to create Datastore  for Azure Data Factory",id:"steps-to-create-datastore--for-azure-data-factory",children:[]}],u={toc:c};function p(t){var e=t.components,i=(0,n.Z)(t,l);return(0,o.kt)("wrapper",(0,a.Z)({},u,i,{components:e,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Azure Data Factory is the platform that solves such data scenarios. It is the cloud-based ETL and data integration service that allows you to create data-driven workflows for orchestrating data movement and transforming data at scale."),(0,o.kt)("p",null,"Guzzle only supports ADF as an External job. "),(0,o.kt)("h2",{id:"steps-to-create-datastore--for-azure-data-factory"},"Steps to create Datastore  for Azure Data Factory"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Click on the action button (",(0,o.kt)("img",{alt:"image alt text",src:r(5745).Z}),") from the ",(0,o.kt)("strong",{parentName:"p"},"Datastores "),"section in Left Navigation and select ",(0,o.kt)("strong",{parentName:"p"},"Azure Data Factory "),"connector. Alternatively users can launch from ",(0,o.kt)("strong",{parentName:"p"},"Create New Datastore "),"link in Activity authoring UI.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter the Datastore name for the new datastore and click Ok")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Update the connection name or leave the default. You can refer to ",(0,o.kt)("a",{parentName:"p",href:"http://http"},"Connection and Environments ")," for more details")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Enter the additional properties for the ADF as described below:"))),(0,o.kt)("table",null,(0,o.kt)("tr",null,(0,o.kt)("td",null,"Property "),(0,o.kt)("td",null,"Description"),(0,o.kt)("td",null,"Required")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Credential Type"),(0,o.kt)("td",null,"Authentication type to use when connecting to ADF. Following mechanisms are supported: Service principal : To use Service principal which to access selected container or folder in the storage account. Follow the steps at Register your application with an Azure AD tenant to create Application Registration and capture following information: Application (client) ID Client secret Directory (Tenant) ID Also ensure following permission: As source: Grant Execute permission for all  parent folders, along with Read permission for the files to copy. Alternatively, in Access control (IAM), grant at least the Storage Blob Data Reader role at container or storage account level As sink: Grant Execute permission for all parents folders, along with Write permission for the sink folders. Alternatively, in Access control (IAM), grant at least the Storage Blob Data Contributor role at container or storage account level."),(0,o.kt)("td",null,"Yes")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Client ID"),(0,o.kt)("td",null,"Service principal\u2019s client id"),(0,o.kt)("td",null,"Yes")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Client Secret"),(0,o.kt)("td",null,"Service principal secret For specify the secret Following mechanisms are supported: Manual : you have to put plain secret in the field Azure Key Vault : To use azure key vault users have to specify the key vault name and secret name of the secure Azure key vault instance. "),(0,o.kt)("td",null,"Yes")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Tenant ID"),(0,o.kt)("td",null,"Directory id of of the service principal "),(0,o.kt)("td",null,"Yes")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Subscription ID"),(0,o.kt)("td",null,"Users Azure subscription Id "),(0,o.kt)("td",null,"Yes")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Resource Group Name"),(0,o.kt)("td",null,"Specify the resource group name under which created Azure Data Factory Instance"),(0,o.kt)("td",null,"Yes")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Factory Name"),(0,o.kt)("td",null,"Specify the name of Data Factory "),(0,o.kt)("td",null,"Yes"))),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"Save the Datastore config. Optionally you can also Test the connection.")))}p.isMDXComponent=!0},5745:function(t,e){"use strict";e.Z="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACQAAAAfCAIAAAAA3/ihAAAAA3NCSVQICAjb4U/gAAAA5UlEQVRIiWNMXXOHgfZgVrAyAwMD49tPX+lgmRAvFwMDA0vqnAN0sGxtoRcDAwMTHWyCg1HLRi0btWyYWcaCR85KTdJMWVxdSnD/tSerjt8Os1TVkRFmYGC48uQthOuoJXPz2ftTd18eu/WcGMvw+cxIUdRWQ0qMjzPcQpWBgcFKVVJbRkhbRshKVZKBgSHcQlWMj9NWQ8pIUZRInw2aYDx3/zULExMkGBkYGI7dfq7zHRqMDAwMK0/chgTjufuvibSMMahvK8UuJgxGq5hRy0YtG7VsSFlG37Z+xS6i6j0KAaQXAwBAp0CiDoMpLQAAAABJRU5ErkJggg=="}}]);