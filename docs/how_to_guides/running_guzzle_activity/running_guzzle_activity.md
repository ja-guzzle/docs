---
id: running_guzzle_activity
title: Running Guzzle Activity
---

### Choose compute
- If you need to run any job in guzzle, first step is to choose compute. Guzzle support many number of compute(Databricks, Glue, synapse) to run the job. For example, if you need to run the job then you need to select respective spark environment(Compute) to run the activity.
- In guzzle, we can set default compute from Guzzle Ui, Click admin top right corner, choose default compute and select your default configured compute.
- Once you selected default compute then guzzle will use this default compute to run all activities. you can overide default compute in Run acitivity popup.

<img width="600" src="/img/docs/how-to-guides/running-guzzle-job/running_job_1.png"/>

### Context Parameter
- In context parameter section, we can override context column parameter like batch, location and business date.
- This option is only visible in guzzle acitivities and pipeline not in batch.

<img width="600" src="/img/docs/how-to-guides/running-guzzle-job/running_job_2.png"/>

### Additional Parameter
- Guzzle allow us to write generic data pipeline, if business logic is same for different pipeline we can use parameter to run same activity with different files. We can set this dynamic parameters in additional paramter section.
- You can pass parameter at activity, pipeline and batch level.

- Additional Parameter in acitivity. 
<img width="600" src="/img/docs/how-to-guides/running-guzzle-job/running_job_3.png"/>

- Additional parameter in pipeline.
<img width="600" src="/img/docs/how-to-guides/running-guzzle-job/running_job_4.png"/>

### Internal parameters
- Guzzle internal parameters


| Parameter | Default Value | Activity | Pipeline | Batch | Description |
|--- |--- |--- |--- |--- |--- |
|batch_id | -1 |Yes|No|No|This parameter is used to overide batch parameter in the job.|
|guzzle.batchpipeline.threads | 4 |Yes|Yes|Yes|When guzzle reads file from the source. Guzzle will create different treads to process the file. For example, Lets say we have 12 file and then using this parameter guzzle will create 3 thread of 4 file in process all files in parallel.   |
|guzzle.ingestion.load_type | Incremental |Yes|Yes|Yes|Guzzle provides watermark support to perform incremental data processing in ingestion module. We can change that behaviour using this parameter. For example, if we dont want to perform incremental load then we can select full load from dropdown|
|hive.storage_format  | ORC |Yes|Yes|Yes|Guzzle support auto create table support in hive datastore, when guzzle internally create hive table by default it uses ORC. Using this parameter we can change data format in hive. |
|job_instance_id| Generated by guzzle |Yes|No|No|We can override job instance id using this parameter.|
|stage_id| -1 |Yes|No|No|Guzzle allow us to override stage_id value of the job|
|guzzle.job_group.partial| False |No|Yes|No| A Pipeline can also be configured to Partial load to allow pipeline execution to continue further even if any jobs within pipelines called in the Pipeline fails. |
|guzzle.job_group.resume| False |No|Yes|Yes | This feature allows to resume the job group or pipeline from where it has failed |


### Retry Properties
- There are instances where activity fails in a pipeline due various reasons like network connectivity or other issue and we want to retry pipeline after it failed.
- This feature is only supported when activity is run as part of pipeline.
- Pipeline is to reattempt the same job before moving to next job (in same execution thread assuming parallel jobs are triggered).
- Retry properties
    - Retry status (Failed): If pipeline in Failed state, guzzle will try the job.
    - Retry interval (seconds)
    - Max retry - Number of time Guzzle will retry pieline.

<img width="600" src="/img/docs/how-to-guides/running-guzzle-job/running_job_11.png"/>

### Timeout Properties
- If your guzzle takes more time then expected then we can force stop guzzle activity using timeout feature.
- Here we have to specify amount of time in second, if guzzle activity is taking longer then given time then guzzle will be timeout and status of guzzle job is failed.